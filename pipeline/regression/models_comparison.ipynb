{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides comparative analysis of the regression models retrived according the three approaches, namely parametric, semi-parametric, and non-parametric regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "from termcolor import colored\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import statistics\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "PROJECT_DIR =Path(os.path.abspath('')).parents[1]\n",
    "sys.path.append(os.fspath(PROJECT_DIR))\n",
    "\n",
    "from pipeline.regression_fx import create_model, realElbows\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import colorsys\n",
    "import matplotlib.colors as mc\n",
    "import itertools\n",
    "\n",
    "from pipeline.definitions import *\n",
    "from localreg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define general parameters for figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_setting=\"notebook\" #or \"article\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if graph_setting==\"article\":\n",
    "    \n",
    "    #journal-quality parameter settings\n",
    "    resolution_factor=2\n",
    "    desired_font=10\n",
    "\n",
    "elif graph_setting==\"notebook\":\n",
    "    resolution_factor=1\n",
    "    desired_font=12\n",
    "\n",
    "#conversion factors\n",
    "cm_to_inch=0.393701\n",
    "classic_proportion=6.4/4.8\n",
    "golden_rate=1.618\n",
    "\n",
    "#Elsevier column width is 8.4 cm, double-column width is 17.7 cm (in inches: 3.31 and 6.97)\n",
    "small_figsize=(resolution_factor*3.31, resolution_factor*3.31/classic_proportion)\n",
    "big_figsize=(resolution_factor*6.97, resolution_factor*6.97/classic_proportion)\n",
    "square_fig=(resolution_factor*4.5, resolution_factor*4.5)\n",
    "\n",
    "#define colors palette\n",
    "colors={}\n",
    "colors[\"P_phys\"]=\"sandybrown\" \n",
    "colors[\"P_semiPar\"]=\"indianred\"\n",
    "colors[\"P_blackbox\"]=\"mediumpurple\"\n",
    "\n",
    "#changings regarding fonttypex\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['font.family'] = \"Arial\"\n",
    "\n",
    "desired_font=10\n",
    "font_size=resolution_factor*desired_font\n",
    "\n",
    "#define path for figures\n",
    "figures_path=FIGURES\n",
    "#check existance of figure path\n",
    "if not os.path.exists(figures_path):\n",
    "    print(\"The selected directory to store figures does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See available case studies\n",
    "dataset_path=DATA_NORMALIZED\n",
    "onlyfiles = [f for f in listdir(dataset_path) if isfile(join(dataset_path, f))]\n",
    "print('The following datasets are available')\n",
    "print(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a case study dataset using pandas\n",
    "method_short=\"ts\" #that is, time serie, or ew, that is elementWise\n",
    "norm_dataset = pd.read_csv(os.path.join(DATA_NORMALIZED, 'norm_'+method_short+'_buildings_dataset.csv'))\n",
    "\n",
    "#load dataset with original measures\n",
    "dataset_name='buildings_dataset_clean.csv'\n",
    "dataset = pd.read_csv(DATA_CLEAN+\"/\"+dataset_name)\n",
    "\n",
    "print(\"Shape of dataset: \"+str(dataset.shape))\n",
    "dataset.tail()\n",
    "#load dataset description\n",
    "data_info=pd.read_csv(DATASETS+\"/\"+'buildings_data_description.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the list of IDs for the case studies, a list for the models and proper matrices to store performance results\n",
    "IDs=norm_dataset.ID.unique()\n",
    "models_name_list=[\"Parametric\", \"Semi-Parametric\", \"Non-Parametric\"]\n",
    "models_list=['P_phys', 'P_semiPar', 'P_blackbox']\n",
    "df_r2=pd.DataFrame(index=pd.MultiIndex.from_product([models_name_list, ['Train', 'Test']]), columns=IDs)\n",
    "df_mape=df_r2.copy()\n",
    "df_mae=df_r2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all the models into a dictionary\n",
    "models={}\n",
    "\n",
    "for caseStudy in IDs:\n",
    "\n",
    "    #check names of the different models for the selected case study\n",
    "    ES_models_list=[f for f in listdir(PAR_MODELS) if isfile(join(PAR_MODELS, f)) and caseStudy in f]\n",
    "    semiPar_submodel_list=[f for f in listdir(SEMIPAR_MODELS) if isfile(join(SEMIPAR_MODELS, f)) and caseStudy in f]\n",
    "    blackbox_models_list=[f for f in listdir(BLACKBOX_MODELS) if isfile(join(BLACKBOX_MODELS, f)) and caseStudy in f]\n",
    "    \n",
    "    #ensure 1 model and no more is available for each case study and model type\n",
    "    if (len(ES_models_list)>1) | (len(semiPar_submodel_list)>1) | (len(blackbox_models_list)>1):\n",
    "        print(colored(\"WARNING: Multiple models have been found for case study \"+caseStudy+\"\\nThe first model in alphabetical order will be loaded\", \"yellow\"))\n",
    "    \n",
    "    if (len(ES_models_list)==0) | (len(semiPar_submodel_list)==0) | (len(blackbox_models_list)==0) :\n",
    "        print(colored(\"ERROR: One or more of the regression model is missing for case study \"+caseStudy+\"\\nThe following models exist for the selected case study: \", \"red\"))\n",
    "        print(pod_models_list)\n",
    "    else: \n",
    "        ES_modelname=ES_models_list[0]\n",
    "        semiPar_modelname=semiPar_submodel_list[0]\n",
    "        blackbox_modelname=blackbox_models_list[0]\n",
    "\n",
    "    #load models\n",
    "    ES_model=tf.keras.models.load_model(PAR_MODELS+'/'+ES_modelname, custom_objects={'realElbows':realElbows})\n",
    "    semiPar_model=tf.keras.models.load_model(SEMIPAR_MODELS+'/'+semiPar_modelname, custom_objects={'realElbows':realElbows})\n",
    "    blackbox_model=tf.keras.models.load_model(BLACKBOX_MODELS+'/'+blackbox_modelname)\n",
    "    models[caseStudy, \"ES\"]=ES_model\n",
    "    models[caseStudy, \"semiPar\"]=semiPar_model\n",
    "    models[caseStudy, \"BlackBox\"]=blackbox_model\n",
    "    #model.summary()\n",
    "\n",
    "print(colored(str(len(models))+\" models have been successfully loaded\", \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models prediction and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output variables\n",
    "ind_var=[\"T_a\", \"RH\", \"Wv\", \"atmP\", \"G\", \"s_Wa\", \"c_Wa\", \"s_H\", \"c_H\", \"s_D\", \"c_D\", \"dayType\"]\n",
    "modeled_ind_var=\"T_a\"\n",
    "dep_var=\"P\"\n",
    "\n",
    "#create new columns in dataset\n",
    "dataset[\"P_phys\"]=np.nan\n",
    "dataset[\"P_res\"]=np.nan\n",
    "dataset[\"P_semiPar\"]=np.nan\n",
    "dataset[\"P_blackbox\"]=np.nan\n",
    "\n",
    "#load scalers\n",
    "directory=DATA\n",
    "file_name=\"scalers_\"+method_short\n",
    "with open(directory+\"/\"+file_name+\".pkl\", 'rb') as f:\n",
    "    scalers_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for caseStudy in IDs:\n",
    "  \n",
    "    #define modeled input\n",
    "    df=norm_dataset.loc[norm_dataset.ID==caseStudy]\n",
    "    df_rescaled=dataset.loc[norm_dataset.ID==caseStudy]\n",
    "    x=pd.DataFrame(df[ind_var])\n",
    "    x_modeled=pd.DataFrame(df[modeled_ind_var])\n",
    "    y=pd.DataFrame(df[dep_var])\n",
    "    \n",
    "    #split test and train \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "    x_modeled_train=pd.DataFrame(x_train[modeled_ind_var])\n",
    "    x_modeled_test=pd.DataFrame(x_test[modeled_ind_var])\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None  # default='warn', use it to hide the SettingCopyWarning\n",
    "    \n",
    "    #predict parametric model output\n",
    "    ES_model=models[caseStudy, \"ES\"]                                              #load model\n",
    "    #x_modeled_NN=scalers_dict[caseStudy, \"x_modeled\"].transform(x_modeled)         #scale input data\n",
    "    #y_NN_pred_ES=ES_model.predict(x_modeled_NN)                                   #predict output\n",
    "    #df[\"P_phys\"]=scalers_dict[caseStudy, \"y\"].inverse_transform(y_NN_pred_ES)     #rescale output\n",
    "    df[\"P_phys\"]=ES_model.predict(x_modeled)  \n",
    "    \n",
    "    #calculate parametric model residuals\n",
    "    df[\"P_res\"]=df[dep_var]-df[\"P_phys\"]\n",
    "    \n",
    "    #predict semi-parametric submodel output\n",
    "    semiPar_model=models[caseStudy, \"semiPar\"]                                   #load model\n",
    "    #x_NN=scalers_dict[caseStudy, \"x\"].transform(x)                                 #scale input data\n",
    "    #y_NN_pred_semiPar=semiPar_model.predict((x_modeled, x), verbose=0) #y_res_NN_pred=nonPar_submodel.predict(x_NN)                                   #predict output\n",
    "    #df[\"P_semiPar\"]=y_res_pred=scalers_dict[caseStudy, \"y_res\"].inverse_transform(y_NN_pred_semiPar)  #rescale output\n",
    "    df[\"P_semiPar\"]=semiPar_model.predict((x_modeled, x), verbose=0)\n",
    "    \n",
    "\n",
    "    #Predict P from black box model\n",
    "    blackbox_model=models[caseStudy, \"BlackBox\"]                                   #load model\n",
    "    #y_NN_pred_bb=blackbox_model.predict(x)                                      #predict output\n",
    "    #df[\"P_blackbox\"]=scalers_dict[caseStudy, \"y\"].inverse_transform(y_NN_pred_bb)  #rescale output\n",
    "    df[\"P_blackbox\"]=blackbox_model.predict(x)  \n",
    "\n",
    "    #store new results\n",
    "    norm_dataset.loc[dataset.ID==caseStudy, \"P_phys\"]=df[\"P_phys\"]\n",
    "    norm_dataset.loc[dataset.ID==caseStudy, \"P_res\"]=df[\"P_res\"]\n",
    "    norm_dataset.loc[dataset.ID==caseStudy, \"P_semiPar\"]=df[\"P_semiPar\"]\n",
    "    norm_dataset.loc[dataset.ID==caseStudy, \"P_blackbox\"]=df[\"P_blackbox\"]\n",
    "\n",
    "    #rescale models' outputs results\n",
    "    df_rescaled[\"P_phys\"]=scalers_dict[caseStudy, \"y\"].inverse_transform(df[\"P_phys\"].values.reshape(-1,1))\n",
    "    df_rescaled[\"P_res\"]=scalers_dict[caseStudy, \"y\"].inverse_transform(df[\"P_res\"].values.reshape(-1,1))\n",
    "    df_rescaled[\"P_semiPar\"]=scalers_dict[caseStudy, \"y\"].inverse_transform(df[\"P_semiPar\"].values.reshape(-1,1))\n",
    "    df_rescaled[\"P_blackbox\"]=scalers_dict[caseStudy, \"y\"].inverse_transform(df[\"P_blackbox\"].values.reshape(-1,1))\n",
    "\n",
    "    #store rescaled results\n",
    "    dataset.loc[dataset.ID==caseStudy, \"P_phys\"]=df_rescaled[\"P_phys\"]\n",
    "    dataset.loc[dataset.ID==caseStudy, \"P_res\"]=df_rescaled[\"P_res\"]\n",
    "    dataset.loc[dataset.ID==caseStudy, \"P_semiPar\"]=df_rescaled[\"P_semiPar\"]\n",
    "    dataset.loc[dataset.ID==caseStudy, \"P_blackbox\"]=df_rescaled[\"P_blackbox\"]\n",
    "    \n",
    "    #for each model calculate the performance achieved on the test set\n",
    "    for model_name, output in zip(models_name_list, [df_rescaled[\"P_phys\"], df_rescaled[\"P_semiPar\"], df_rescaled[\"P_blackbox\"]]):\n",
    "        x=df_rescaled[\"T_a\"]\n",
    "        y_true=df_rescaled[\"P\"]\n",
    "        _, _, y_true_train, y_true_test = train_test_split(x, y_true, test_size=0.33, random_state=42)\n",
    "        y_pred=output\n",
    "        _, _, y_pred_train, y_pred_test = train_test_split(x, y_pred, test_size=0.33, random_state=42)\n",
    "        #store regression models performance\n",
    "        df_r2.loc[model_name, 'Train'][caseStudy]=r2_score(y_true_train, y_pred_train)\n",
    "        df_r2.loc[model_name, 'Test'][caseStudy] =r2_score(y_true_test, y_pred_test)\n",
    "        \n",
    "        df_mape.loc[model_name, 'Train'][caseStudy]=mean_absolute_percentage_error(y_true_train, y_pred_train)\n",
    "        df_mape.loc[model_name, 'Test'][caseStudy] =mean_absolute_percentage_error(y_true_test, y_pred_test)\n",
    "        \n",
    "        df_mae.loc[model_name, 'Train'][caseStudy]=mean_absolute_error(y_true_train, y_pred_train)\n",
    "        df_mae.loc[model_name, 'Test'][caseStudy] =mean_absolute_error(y_true_test, y_pred_test)\n",
    "\n",
    "print(colored(\"Predictions from the regression models correctly retrieved\", \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show summary of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of performance results\n",
    "res_summary=pd.DataFrame(index=df_r2.index, columns=[\"R2\", \"MAE\", \"MAPE\"])\n",
    "for model, model_name in zip(models_list, models_name_list):\n",
    "    res_summary[\"R2\"]=df_r2.mean(axis=1)\n",
    "    res_summary[\"MAPE\"]=df_mape.mean(axis=1)\n",
    "    res_summary[\"MAE\"]=df_mae.mean(axis=1)\n",
    "#calculate std of performance results \n",
    "res_std=pd.DataFrame(index=df_r2.index, columns=[\"R2\", \"MAE\", \"MAPE\"])\n",
    "for model, model_name in zip(models_list, models_name_list):\n",
    "    res_std[\"R2\"]=df_r2.std(axis=1)\n",
    "    res_std[\"MAPE\"]=df_mape.std(axis=1)\n",
    "    res_std[\"MAE\"]=df_mae.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.3}\".format\n",
    "print(\"Mean values accross the different case studies\")\n",
    "display(res_summary)\n",
    "\n",
    "print(\"Standard deviation the different case studies\")\n",
    "display(res_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare predictions from the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select cases studies\n",
    "caseStudy_B=IDs[0]\n",
    "caseStudy_C=IDs[1]\n",
    "caseStudy_list=[caseStudy_B, caseStudy_C]\n",
    "\n",
    "#initializa graphical obnject\n",
    "fig, (ax1, ax2) = plt.subplots(2, 3, figsize=big_figsize)\n",
    "subplot_pos_list=[231, 232, 233, 234, 235, 236]\n",
    "\n",
    "#define title and subtitles\n",
    "subtitle={}\n",
    "subtitle[models_list[0]], subtitle[models_list[1]], subtitle[models_list[2]]=models_name_list\n",
    "\n",
    "for case, subplot_pos in zip(list(itertools.product(caseStudy_list, models_list)), subplot_pos_list): #this cycle iterate over 6 combinations of modeltype*casestudy\n",
    "    caseStudy=case[0]\n",
    "    model=case[1]\n",
    "    model_name=subtitle[model]\n",
    "    \n",
    "    #define modeled input\n",
    "    df=dataset.loc[dataset.ID==caseStudy]\n",
    "    scaler_y=scalers_dict[caseStudy, \"y\"]\n",
    "    y_pred=scaler_y.transform(pd.DataFrame(df[model].values, columns=[\"P\"]))\n",
    "    y_real=scaler_y.transform(pd.DataFrame(df[\"P\"]))\n",
    "\n",
    "    #get limit y value\n",
    "    p1 = max(max(y_pred), max(y_real))\n",
    "    p2 = min(min(y_pred), min(y_real))\n",
    "\n",
    "    #access to specific subplot\n",
    "    ax=plt.subplot(subplot_pos)\n",
    "\n",
    "    #scatter predictions\n",
    "    ax.scatter(y_real, y_pred, s=1.5, color=colors[model])\n",
    "    ax.plot([p1, p2], [p1, p2], color=\"black\", linestyle='--')\n",
    "\n",
    "    #graphical custom options\n",
    "    ax.grid(True, which='both',axis='both',alpha=0.5, linewidth=0.45)\n",
    "    ax.tick_params(labelsize=font_size-2)\n",
    "    ticks=[0, 0.25, 0.5, 0.75, 1]\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "\n",
    "    #arrange image details (ticks, tickslabels and titles)\n",
    "    if subplot_pos!=234:\n",
    "        if subplot_pos not in [235, 236]:\n",
    "            ax.tick_params(axis='x',which='both',length=0.1,width=0.1,pad=1)\n",
    "            ax.set_xticklabels([])\n",
    "        if subplot_pos!=231:\n",
    "            ax.tick_params(axis='y',which='both',length=0.1,width=0.1,pad=1)\n",
    "            ax.set_yticklabels([])\n",
    "    if subplot_pos in [231, 232, 233]:  \n",
    "        ax.set_title(model_name, fontsize=font_size)\n",
    "    if subplot_pos==231:\n",
    "        ax.set_ylabel(\"a)\", fontsize=font_size-2, rotation=0)\n",
    "        ax.yaxis.set_label_coords(-0.25, +0.5)\n",
    "    elif subplot_pos==234:\n",
    "        ax.set_ylabel(\"b)\", fontsize=font_size-2, rotation=0)\n",
    "        ax.yaxis.set_label_coords(-0.25, +0.5)\n",
    "\n",
    "    #print performance for the selected case study and model\n",
    "    print(\"\\nCase study: \"+caseStudy)\n",
    "    print(\"Model: \"+model_name+ \"\\nMAPE:\"+str(df_mape.loc[model_name, 'Test'][caseStudy]))\n",
    "    print(\"R2:\"+str(df_r2.loc[model_name, 'Test'][caseStudy]))\n",
    "    \n",
    "\n",
    "\n",
    "text_x=fig.supxlabel('True Values [-]', y=0.02, fontsize=font_size)\n",
    "text_y=fig.supylabel('Predictions [-]', x=0.02, fontsize=font_size)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.03*resolution_factor, hspace=0.03*resolution_factor)\n",
    "plt.show()\n",
    "#fig.savefig(figures_path+\"/models_forecast_comparison_2_buildings\", bbox_extra_artists=(text_x, text_y), bbox_inches='tight', dpi=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a case Study\n",
    "caseStudy=IDs[1]\n",
    "print(caseStudy)\n",
    "df=dataset.loc[dataset.ID==caseStudy]\n",
    "df_corr=df.drop([\"ID\", \"P_res\", \"P_phys\", \"P_semiPar\", \"P_blackbox\"], axis=1).corr()\n",
    "\n",
    "#change order of the variables to be visualized in the heatmap\n",
    "df_corr=df_corr.loc[[\"P\", 'T_a', 'T_b', 'DP', 'RH', 'Wv', 'Wgv', 'atmP', 'G', 's_Wa', 'c_Wa',\n",
    "       's_H', 'c_H', 'dayType', 's_D', 'c_D'], [\"P\", 'T_a', 'T_b', 'DP', 'RH', 'Wv', 'Wgv', 'atmP', 'G', 's_Wa', 'c_Wa',\n",
    "       's_H', 'c_H', 'dayType', 's_D', 'c_D']]\n",
    "\n",
    "#graphical representation of predictions accuracy\n",
    "grid_spec = {\"width_ratios\": (.98, .04), \"wspace\": 0.15}\n",
    "\n",
    "fig, (ax, cbar_ax) = plt.subplots(1,2, figsize=square_fig,   gridspec_kw=grid_spec)\n",
    "#create heat map\n",
    "ax=sns.heatmap(df_corr, vmin=0.0, vmax=1.0, ax=ax, square=True, cbar_ax=cbar_ax, cbar_kws={'label': 'Pearson Correlation Coefficient [-]'})\n",
    "cbar_ax.yaxis.label.set_size(font_size)\n",
    "cbar_ax.tick_params(labelsize=font_size)\n",
    "ax.tick_params(labelsize=font_size)\n",
    "#ax.set_title(\"Correlation Matrix\", fontsize=font_size)\n",
    "\n",
    "#fig.savefig(figures_path+\"/full_correlation_matrix\", bbox_inches='tight', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select reduced features for correlation analysis of power and power residuals\n",
    "df_corr=df.drop([\"ID\"], axis=1).corr()\n",
    "reduced_df_corr=df_corr.loc[[\"P\", \"P_phys\", \"P_res\"], [\"P\", \"P_phys\", \"P_res\", 'T_a', 'T_b', 'DP', 'RH', 'Wv', 'Wgv', 'atmP', 'G', 's_Wa', 'c_Wa',\n",
    "       's_H', 'c_H', 'dayType', 's_D', 'c_D']]\n",
    "\n",
    "\n",
    "fig, ax= plt.subplots(1, figsize=square_fig)\n",
    "#create heat map\n",
    "ax=sns.heatmap(reduced_df_corr, vmin=0.0, vmax=1.0, ax=ax, square=True, cbar=False)\n",
    "ax.tick_params(labelsize=font_size)\n",
    "#ax.set_title(\"Correlation Matrix\", fontsize=font_size)\n",
    "\n",
    "#fig.savefig(figures_path+\"/reduced_correlation_matrix\",  bbox_inches='tight', dpi=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-parametric VS Parametric model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define general parameters for plot\n",
    "show_title=\"No\"\n",
    "show_labels=\"No\"\n",
    "show_ticks=\"Partial\"\n",
    "limit_x_axis = None\n",
    "limit_y_axis = None\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=big_figsize, layout='constrained')\n",
    "\n",
    "#select case study\n",
    "caseStudy=IDs[0]\n",
    "print(caseStudy)\n",
    "df=dataset.loc[dataset.ID==caseStudy]\n",
    "\n",
    "#select inputs and outputs from the parametric and semiparametric model\n",
    "x=df[ind_var]\n",
    "y=df[\"P\"]\n",
    "y_pred=df[\"P_semiPar\"]\n",
    "y_ref_line=df[\"P_phys\"]\n",
    "explanatory_var=\"T_a\"\n",
    "\n",
    "#re-order dataset according to Temperature\n",
    "ordered_df=df.copy()\n",
    "ordered_df['y_pred']=y_pred.values    \n",
    "ordered_df=ordered_df.sort_values(by=explanatory_var)\n",
    "\n",
    "#plot models outputs\n",
    "points=[]    #create a list to store graphical elements to later show the legend\n",
    "#plot real points\n",
    "real_points=ax.scatter(df[explanatory_var], df[dep_var], color=\"gray\", alpha=0.6, s=1.5*resolution_factor)\n",
    "points.append(real_points)\n",
    "#plot points predicted by the semi-parametric model\n",
    "pred_points=ax.scatter(ordered_df[explanatory_var], ordered_df[\"y_pred\"], color=colors['P_semiPar'], marker='x', s=1.5*resolution_factor, alpha=0.8)\n",
    "points.append(pred_points)\n",
    "#plot the line predicted by the semi-parametric model\n",
    "ref_line=ordered_df[\"P_phys\"].values\n",
    "line,=ax.plot(ordered_df[explanatory_var], ref_line, color=colors[\"P_phys\"], zorder=3, linewidth=2*resolution_factor) #zorder is used to define the order elements are plot\n",
    "points.append(line)\n",
    "\n",
    "#graphical custom options\n",
    "ax.grid(True, which='both',axis='both',alpha=0.5, linewidth=0.45)\n",
    "ax.tick_params(labelsize=font_size)\n",
    "ax.set_xlabel('Outdoor Temperature [°C]', size=font_size)\n",
    "ax.set_ylabel('Normalized\\n Electrical Load [-]', size=font_size)\n",
    "legend=fig.legend(points, [\"Real Values\", \"SPM predictions\", \"PM predictions\"], ncol=1, labelspacing=0., bbox_to_anchor=(0.98, 0.35), fontsize=font_size)\n",
    "\n",
    "#fig.savefig(figures_path+\"/ES_style_model_forecast\",  bbox_inches='tight', dpi=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the impact of Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figures will compare the regression line of parametric models and a projection of the predictions of the semiparametric model to estimate the cualitative impact of temperature for this model. The projections are obtained by using a smoothing function, by means of a local regression. \n",
    "\n",
    "The goal of this comparative analysis is to detect possible deviations of the complex behavior, with respect to temperature, modelled by the semi parametric model, from the one that was previously modeled by means of the parametric model (Energy Signature model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define general parameters for plot\n",
    "show_title=\"No\"\n",
    "show_labels=\"No\"\n",
    "show_ticks=\"Partial\"\n",
    "limit_x_axis = None\n",
    "limit_y_axis = None\n",
    "\n",
    "\n",
    "\n",
    "#select case studies\n",
    "caseStudies=[IDs[0], IDs[1]]\n",
    "\n",
    "fig, axs = plt.subplots(len(caseStudies), 1, figsize=(big_figsize[0], big_figsize[1]*len(caseStudies)), layout='constrained')\n",
    "\n",
    "for caseStudy, ax in zip(caseStudies, axs.flatten()):\n",
    "    \n",
    "    #select inputs and outputs from the parametric and semiparametric model\n",
    "    df=dataset.loc[dataset.ID==caseStudy]\n",
    "    x=df[ind_var]\n",
    "    y=df[\"P\"]\n",
    "    y_pred=df[\"P_semiPar\"]\n",
    "    y_ref_line=df[\"P_phys\"]\n",
    "    explanatory_var=\"T_a\"\n",
    "\n",
    "    #re-order dataset according to Temperature\n",
    "    ordered_df=df.copy()\n",
    "    ordered_df['y_pred']=y_pred.values    \n",
    "    ordered_df=ordered_df.sort_values(by=explanatory_var)\n",
    "    \n",
    "    points=[]      #create a list to store graphical elements to later show the legend\n",
    "    #plot real points\n",
    "    real_points=ax.scatter(df[explanatory_var], df[dep_var], color=\"gray\", alpha=0.6, s=1.5*resolution_factor)\n",
    "    points.append(real_points)\n",
    "\n",
    "    #get reference line of parametric model\n",
    "    ref_line_Par=ordered_df[\"P_phys\"].values\n",
    "    \n",
    "    #define reference line of semi-parametric model by smoothing the prediction points\n",
    "    ref_line_semiPar=localreg(ordered_df[explanatory_var].values, ordered_df['P_semiPar'].values, degree=1, kernel=rbf.epanechnikov, frac=0.15)\n",
    "    \n",
    "    #plot lines\n",
    "    line_par,=ax.plot(ordered_df[explanatory_var], ref_line_Par, color=colors[\"P_phys\"], zorder=3, linewidth=1.8*resolution_factor) #zorder is used to define the order elements are plot\n",
    "    line_semiPar,=ax.plot(ordered_df[explanatory_var], ref_line_semiPar, color=colors[\"P_semiPar\"], zorder=3, linewidth=1.8*resolution_factor) #zorder is used to define the order elements are plot\n",
    "    points.extend([line_par, line_semiPar])\n",
    "    \n",
    "    #graphical custom options\n",
    "    ax.grid(True, which='both',axis='both',alpha=0.5, linewidth=0.45)\n",
    "    ax.tick_params(labelsize=font_size)\n",
    "    ax.set_xlabel('Outdoor Temperature [°C]', size=font_size)\n",
    "    ax.set_ylabel('Normalized\\n Electrical Load [-]', size=font_size)\n",
    "    legend=fig.legend(points, [\"Real Values\", \"PM predictions\", \"SPM predictions\", \"NPM predictions\"], ncol=1, labelspacing=0., bbox_to_anchor=(0.85, 0.97), fontsize=font_size)\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "#fig.savefig(figures_path+\"/deviation_temperature_impact_2_buildings\", bbox_inches='tight', dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "88688c6e448969839ee4163a6b670935eee153233d49c269b97f67337e0696f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
